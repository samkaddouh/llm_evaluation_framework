# llm_evaluation_framework
Help evaluate LLM-powered agents: design rubrics, human-in-the-loop studies, and guardrail canaries.
